{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "967e41f0-a0b0-480b-93ff-71ab4cc50162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.3\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b05b62-36c8-4855-a5f5-98df9ad6e0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1288ef63-6a60-40ee-9b27-ea0a4a782150",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join('.', 'daily_push', 'data', 'Gangnam3Districts_Boundary_Center.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4610f045-687e-474e-81f7-5c99290011d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3700397/3247070780.py:4: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  강남3구_집계구_경계_중심 = pickle.load(f)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gu</th>\n",
       "      <th>TOT_REG_CD</th>\n",
       "      <th>geometry</th>\n",
       "      <th>count</th>\n",
       "      <th>centroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11220</td>\n",
       "      <td>11220520010107</td>\n",
       "      <td>POLYGON ((127.02654 37.48948, 127.02601 37.489...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>POINT (127.02621 37.48978)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11220</td>\n",
       "      <td>11220590020102</td>\n",
       "      <td>POLYGON ((127.00201 37.5079, 127.00223 37.5074...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>POINT (127.00173 37.50763)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11220</td>\n",
       "      <td>11220670020002</td>\n",
       "      <td>POLYGON ((127.03551 37.46515, 127.03539 37.464...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>POINT (127.0478 37.44425)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11220</td>\n",
       "      <td>11220680030001</td>\n",
       "      <td>POLYGON ((127.07618 37.45624, 127.07639 37.456...</td>\n",
       "      <td>116.0</td>\n",
       "      <td>POINT (127.06819 37.44481)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11220</td>\n",
       "      <td>11220540010106</td>\n",
       "      <td>POLYGON ((127.02177 37.50081, 127.02166 37.500...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>POINT (127.02117 37.50097)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3067</th>\n",
       "      <td>11240</td>\n",
       "      <td>11240540010801</td>\n",
       "      <td>POLYGON ((127.14493 37.48965, 127.14463 37.488...</td>\n",
       "      <td>146.0</td>\n",
       "      <td>POINT (127.14401 37.48973)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3068</th>\n",
       "      <td>11240</td>\n",
       "      <td>11240590030105</td>\n",
       "      <td>POLYGON ((127.14341 37.51721, 127.14356 37.517...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>POINT (127.14088 37.51645)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>11240</td>\n",
       "      <td>11240590040102</td>\n",
       "      <td>POLYGON ((127.13568 37.51516, 127.13544 37.514...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>POINT (127.13466 37.51537)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>11240</td>\n",
       "      <td>11240820010202</td>\n",
       "      <td>POLYGON ((127.14042 37.48346, 127.14018 37.482...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>POINT (127.13148 37.47358)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>11240</td>\n",
       "      <td>11240520011202</td>\n",
       "      <td>POLYGON ((127.11662 37.53141, 127.11657 37.531...</td>\n",
       "      <td>118.0</td>\n",
       "      <td>POINT (127.11645 37.53175)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2704 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gu      TOT_REG_CD  \\\n",
       "0     11220  11220520010107   \n",
       "1     11220  11220590020102   \n",
       "2     11220  11220670020002   \n",
       "3     11220  11220680030001   \n",
       "4     11220  11220540010106   \n",
       "...     ...             ...   \n",
       "3067  11240  11240540010801   \n",
       "3068  11240  11240590030105   \n",
       "3069  11240  11240590040102   \n",
       "3070  11240  11240820010202   \n",
       "3071  11240  11240520011202   \n",
       "\n",
       "                                               geometry  count  \\\n",
       "0     POLYGON ((127.02654 37.48948, 127.02601 37.489...   53.0   \n",
       "1     POLYGON ((127.00201 37.5079, 127.00223 37.5074...   54.0   \n",
       "2     POLYGON ((127.03551 37.46515, 127.03539 37.464...  114.0   \n",
       "3     POLYGON ((127.07618 37.45624, 127.07639 37.456...  116.0   \n",
       "4     POLYGON ((127.02177 37.50081, 127.02166 37.500...   60.0   \n",
       "...                                                 ...    ...   \n",
       "3067  POLYGON ((127.14493 37.48965, 127.14463 37.488...  146.0   \n",
       "3068  POLYGON ((127.14341 37.51721, 127.14356 37.517...   63.0   \n",
       "3069  POLYGON ((127.13568 37.51516, 127.13544 37.514...   51.0   \n",
       "3070  POLYGON ((127.14042 37.48346, 127.14018 37.482...   66.0   \n",
       "3071  POLYGON ((127.11662 37.53141, 127.11657 37.531...  118.0   \n",
       "\n",
       "                        centroid  \n",
       "0     POINT (127.02621 37.48978)  \n",
       "1     POINT (127.00173 37.50763)  \n",
       "2      POINT (127.0478 37.44425)  \n",
       "3     POINT (127.06819 37.44481)  \n",
       "4     POINT (127.02117 37.50097)  \n",
       "...                          ...  \n",
       "3067  POINT (127.14401 37.48973)  \n",
       "3068  POINT (127.14088 37.51645)  \n",
       "3069  POINT (127.13466 37.51537)  \n",
       "3070  POINT (127.13148 37.47358)  \n",
       "3071  POINT (127.11645 37.53175)  \n",
       "\n",
       "[2704 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "with open(os.path.join('.', 'daily_push', 'data', 'Gangnam3Districts_Boundary_Center.pickle'), 'rb') as f:\n",
    "    강남3구_집계구_경계_중심 = pickle.load(f)\n",
    "강남3구_집계구_경계_중심"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3505ff88-c8e6-4fd3-8e54-176620f00d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?><response><header><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><items><item><dateKind>01</dateKind><dateName>1\\xec\\x9b\\x941\\xec\\x9d\\xbc</dateName><isHoliday>Y</isHoliday><locdate>20220101</locdate><seq>1</seq></item><item><dateKind>01</dateKind><dateName>\\xec\\x84\\xa4\\xeb\\x82\\xa0</dateName><isHoliday>Y</isHoliday><locdate>20220131</locdate><seq>1</seq></item><item><dateKind>01</dateKind><dateName>\\xec\\x84\\xa4\\xeb\\x82\\xa0</dateName><isHoliday>Y</isHoliday><locdate>20220201</locdate><seq>1</seq></item><item><dateKind>01</dateKind><dateName>\\xec\\x84\\xa4\\xeb\\x82\\xa0</dateName><isHoliday>Y</isHoliday><locdate>20220202</locdate><seq>1</seq></item><item><dateKind>01</dateKind><dateName>\\xec\\x82\\xbc\\xec\\x9d\\xbc\\xec\\xa0\\x88</dateName><isHoliday>Y</isHoliday><locdate>20220301</locdate><seq>1</seq></item><item><dateKind>01</dateKind><dateName>\\xeb\\x8c\\x80\\xed\\x86\\xb5\\xeb\\xa0\\xb9\\xec\\x84\\xa0\\xea\\xb1\\xb0\\xec\\x9d\\xbc</dateName><isHoliday>Y</isHoliday><locdate>20220309</locdate><seq>1</seq></item><item><dateKind>01</dateKind><dateName>\\xec\\x96\\xb4\\xeb\\xa6\\xb0\\xec\\x9d\\xb4\\xeb\\x82\\xa0</dateName><isHoliday>Y</isHoliday><locdate>20220505</locdate><seq>1</seq></item><item><dateKind>01</dateKind><dateName>\\xeb\\xb6\\x80\\xec\\xb2\\x98\\xeb\\x8b\\x98\\xec\\x98\\xa4\\xec\\x8b\\xa0\\xeb\\x82\\xa0</dateName><isHoliday>Y</isHoliday><locdate>20220508</locdate><seq>1</seq></item><item><dateKind>01</dateKind><dateName>\\xec\\xa0\\x84\\xea\\xb5\\xad\\xeb\\x8f\\x99\\xec\\x8b\\x9c\\xec\\xa7\\x80\\xeb\\xb0\\xa9\\xec\\x84\\xa0\\xea\\xb1\\xb0</dateName><isHoliday>Y</isHoliday><locdate>20220601</locdate><seq>1</seq></item><item><dateKind>01</dateKind><dateName>\\xed\\x98\\x84\\xec\\xb6\\xa9\\xec\\x9d\\xbc</dateName><isHoliday>Y</isHoliday><locdate>20220606</locdate><seq>1</seq></item><item><dateKind>01</dateKind><dateName>\\xea\\xb4\\x91\\xeb\\xb3\\xb5\\xec\\xa0\\x88</dateName><isHoliday>Y</isHoliday><locdate>20220815</locdate><seq>1</seq></item><item><dateKind>01</dateKind><dateName>\\xec\\xb6\\x94\\xec\\x84\\x9d</dateName><isHoliday>Y</isHoliday><locdate>20220909</locdate><seq>1</seq></item><item><dateKind>01</dateKind><dateName>\\xec\\xb6\\x94\\xec\\x84\\x9d</dateName><isHoliday>Y</isHoliday><locdate>20220910</locdate><seq>1</seq></item><item><dateKind>01</dateKind><dateName>\\xec\\xb6\\x94\\xec\\x84\\x9d</dateName><isHoliday>Y</isHoliday><locdate>20220911</locdate><seq>1</seq></item><item><dateKind>01</dateKind><dateName>\\xeb\\x8c\\x80\\xec\\xb2\\xb4\\xea\\xb3\\xb5\\xed\\x9c\\xb4\\xec\\x9d\\xbc</dateName><isHoliday>Y</isHoliday><locdate>20220912</locdate><seq>1</seq></item><item><dateKind>01</dateKind><dateName>\\xea\\xb0\\x9c\\xec\\xb2\\x9c\\xec\\xa0\\x88</dateName><isHoliday>Y</isHoliday><locdate>20221003</locdate><seq>1</seq></item><item><dateKind>01</dateKind><dateName>\\xed\\x95\\x9c\\xea\\xb8\\x80\\xeb\\x82\\xa0</dateName><isHoliday>Y</isHoliday><locdate>20221009</locdate><seq>1</seq></item><item><dateKind>01</dateKind><dateName>\\xeb\\x8c\\x80\\xec\\xb2\\xb4\\xea\\xb3\\xb5\\xed\\x9c\\xb4\\xec\\x9d\\xbc</dateName><isHoliday>Y</isHoliday><locdate>20221010</locdate><seq>3</seq></item><item><dateKind>01</dateKind><dateName>\\xea\\xb8\\xb0\\xeb\\x8f\\x85\\xed\\x83\\x84\\xec\\x8b\\xa0\\xec\\x9d\\xbc</dateName><isHoliday>Y</isHoliday><locdate>20221225</locdate><seq>1</seq></item></items><numOfRows>30</numOfRows><pageNo>1</pageNo><totalCount>19</totalCount></body></response>'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "공휴일_url = 'http://apis.data.go.kr/B090041/openapi/service/SpcdeInfoService/getRestDeInfo'\n",
    "공휴일_params ={'serviceKey' : 'z1DJA6Ag86kdealhvEpwafaXLI8NEGWSThqDqdsBzHaeGYVI83kcGrdTnAfRBcohutSUt2l6/NSYR6lMF31ZNg==', \n",
    "             # z1DJA6Ag86kdealhvEpwafaXLI8NEGWSThqDqdsBzHaeGYVI83kcGrdTnAfRBcohutSUt2l6%2FNSYR6lMF31ZNg%3D%3D\n",
    "         'solYear' : '2022', 'numOfRows' : '30', \n",
    "             # '_type': 'json' \n",
    "            }\n",
    "공휴일_response = requests.get(공휴일_url, params = 공휴일_params)\n",
    "result = 공휴일_response.content\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b8e5a1f-f0f8-44c0-b780-fb81b8f44841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n",
      "/home/yspark/driving-teacher-ai/dags/model_train_deploy/lib/utils.py:231: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key],\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "working_dir = os.getcwd()\n",
    "\n",
    "sys.path.append(working_dir)\n",
    "from model_train_deploy.lib.db_io import Engine\n",
    "from model_train_deploy.lib.utils import 구분데이터붙이기, 군집나누기\n",
    "from model_train_deploy.lib.simulator_02 import Cluster\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.stats import ks_2samp\n",
    "from sqlalchemy import text\n",
    "\n",
    "db_info = {'host': '163.152.172.163',\n",
    "          'port': '5432',\n",
    "          'db_name': 'postgres',\n",
    "          'user_name': 'tgsociety',\n",
    "          'password': 'tgsociety'}\n",
    "execution_date = '2024-07-19 23:00:00+09'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def measure_drift(execution_date):\n",
    "execution_date = pd.to_datetime(execution_date)\n",
    "db_handler = Engine(db_info)\n",
    "\n",
    "query = '''\n",
    "    SELECT *\n",
    "    FROM datamart.history_학습id\n",
    "    ORDER BY 등록일시 DESC\n",
    "    LIMIT 1\n",
    "'''\n",
    "train_history = pd.read_sql(query, db_handler.engine)\n",
    "\n",
    "new_query = '''\n",
    "SELECT *\n",
    "FROM datamart.고객수요\n",
    "WHERE 예약희망일시 >= %(st_dt)s\n",
    "    and 예약희망일시 <= %(ed_dt)s\n",
    "'''\n",
    "# 새로운 데이터 불러오기\n",
    "ref_data = pd.read_sql(new_query, db_handler.engine, params={'st_dt': train_history.loc[0, 'train_data_start_dt'], 'ed_dt': train_history.loc[0, 'train_data_end_dt']})\n",
    "ref_data['예약희망일시'] = ref_data['예약희망일시'].dt.tz_convert('Asia/Seoul')\n",
    "ref_data['고객_접속일시'] = ref_data['고객_접속일시'].dt.tz_convert('Asia/Seoul')\n",
    "\n",
    "cur_data = pd.read_sql(new_query, db_handler.engine, params={'st_dt': train_history.loc[0, 'train_data_start_dt'], 'ed_dt': execution_date})\n",
    "cur_data['예약희망일시'] = cur_data['예약희망일시'].dt.tz_convert('Asia/Seoul')\n",
    "cur_data['고객_접속일시'] = cur_data['고객_접속일시'].dt.tz_convert('Asia/Seoul')\n",
    "query = '''\n",
    "SELECT demand_cluster_pickle\n",
    "FROM datamart.storage_demand_cluster\n",
    "WHERE train_id = %(train_id)s\n",
    "'''\n",
    "\n",
    "# 쿼리 실행 및 데이터 불러오기\n",
    "tmp_df = pd.read_sql(query, db_handler.engine, params={'train_id': int(train_history.loc[0, 'train_id'])})\n",
    "\n",
    "클러스터링결과 = pickle.loads(tmp_df.loc[0, 'demand_cluster_pickle'])\n",
    "# 클러스터링결과['cluster'] = self.cluster\n",
    "# 클러스터링결과['hierarchy_sample_data'] = self.hierarchy_sample_data\n",
    "\n",
    "ref_data = 구분데이터붙이기(ref_data.copy(), '예약희망일시')\n",
    "cur_data = 구분데이터붙이기(cur_data.copy(), '예약희망일시')\n",
    "\n",
    "군집_ref_data = 군집나누기(ref_data.copy(), 클러스터링결과['cluster'].군집s)\n",
    "군집_cur_data = 군집나누기(cur_data.copy(), 클러스터링결과['cluster'].군집s)\n",
    "\n",
    "p_values = []\n",
    "for key in list(군집_ref_data):\n",
    "    if (len(군집_ref_data[key])==0) & (len(군집_cur_data[key])==0):\n",
    "        p_values.append(1)\n",
    "    elif (len(군집_ref_data[key])==0) | (len(군집_cur_data[key])==0):\n",
    "        p_values.append(0)\n",
    "    else:\n",
    "        p_values.append(ks_2samp(군집_ref_data[key][:int(len(군집_ref_data[key])/2)], 군집_cur_data[key])[1].item())\n",
    "\n",
    "        \n",
    "data_start_dt = train_history.loc[0, 'train_data_start_dt']\n",
    "data_end_dt = cur_data.sort_values(by = '예약희망일시', ascending = False).reset_index(drop=True).loc[0, '예약희망일시']\n",
    "\n",
    "insert_query = text('''INSERT INTO datamart.\"history_드리프트id\" (\"drift_data_start_dt\", \"drift_data_end_dt\", \"logical_dt\") VALUES (:st, :ed, :logi) RETURNING \"drift_id\";''')\n",
    "\n",
    "with db_handler.engine.connect() as connection:\n",
    "    trans = connection.begin()\n",
    "    result = connection.execute(insert_query, {'st': data_start_dt, 'ed': data_end_dt, 'logi': execution_date})\n",
    "    \n",
    "    # 생성된 id 값을 가져옴\n",
    "    drift_id = result.scalar()\n",
    "    trans.commit()\n",
    "\n",
    "tmp_df = pd.DataFrame(columns = ['drift_id', 'train_id', 'cluster_num', 'drift_method', 'drift_value', 'drift_yn'])\n",
    "cluster_nums = []\n",
    "drift_values = []\n",
    "drift_yns = []\n",
    "for i, p in enumerate(p_values):\n",
    "    cluster_nums.append(i)\n",
    "    drift_values.append(p)\n",
    "    drift_yns.append(p <= 0.05)\n",
    "tmp_df = pd.DataFrame({\n",
    "    'drift_id': [drift_id]*len(p_values),\n",
    "    'train_id': [int(train_history.loc[0, 'train_id'])]*len(p_values),\n",
    "    'cluster_num': cluster_nums,\n",
    "    'drift_method': ['Kolmogorov_Smirnov Test']*len(p_values),\n",
    "    'drift_value': drift_values,\n",
    "    'drift_yn': drift_yns\n",
    "})\n",
    "tmp_df.to_sql('result_drift', db_handler.engine, schema = 'datamart', index = False, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dee83611-df6f-47f9-9aaf-a3428af975a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40355354646300684"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "ks_2samp([0,0,1,0,0]*30, [0,0,0,0,1,1]*10)[1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea6f835b-9d46-4050-b285-a969e489086b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drift_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c50ac00-5b1d-414c-91a0-c9824cf3c809",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data passed to ks_2samp must not be empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_277909/123903910.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mks_2samp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m군집_ref_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;31m# if len(군집_ref_data[key]) >1:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mks_2samp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m군집_ref_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m군집_ref_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m군집_cur_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_make_data_3/lib/python3.9/site-packages/scipy/stats/_axis_nan_policy.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0;31m# behavior of those would break backward compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msentinel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_remove_sentinel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaired\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentinel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhypotest_fun_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_add_reduced_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduced_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtuple_to_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_make_data_3/lib/python3.9/site-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m                     message = (f\"{fun.__name__}() got multiple values for \"\n\u001b[1;32m    791\u001b[0m                                f\"argument now known as `{new_name}`\")\n\u001b[1;32m    792\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/test_make_data_3/lib/python3.9/site-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(data1, data2, alternative, method)\u001b[0m\n\u001b[1;32m   8740\u001b[0m     \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8741\u001b[0m     \u001b[0mn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8742\u001b[0m     \u001b[0mn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8743\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8744\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data passed to ks_2samp must not be empty'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8746\u001b[0m     \u001b[0mdata_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8747\u001b[0m     \u001b[0;31m# using searchsorted solves equal data problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data passed to ks_2samp must not be empty"
     ]
    }
   ],
   "source": [
    "\n",
    "for key in list(군집_ref_data):\n",
    "    # if len(군집_ref_data[key]) >1:\n",
    "    print(ks_2samp(군집_ref_data[key][:int(len(군집_ref_data[key])/2)], 군집_cur_data[key])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12649976-fb48-44ef-a038-4d0d8e4ea56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def 군집나누기(data, 군집):\n",
    "    '''\n",
    "    data는 구분데이터붙이기가 돼어있어야함.\n",
    "    군집은 cluster.군집s를 불러와야함.\n",
    "    '''\n",
    "    hierarchy_sample_data = {}\n",
    "    for key in list(군집):\n",
    "        hierarchy_sample_data[key] = pd.DataFrame(columns = ['고객_접속일시', '예약희망일시', '예약희망_point', '연월일', '연', '월', '요일', '공휴일', '시간대'])\n",
    "        for condition in eval(key):\n",
    "            condition1 = (data['월'] == condition[0])\n",
    "            condition2 = (data['요일'] == condition[1])\n",
    "            condition3 = (data['공휴일'] == condition[2])\n",
    "            condition4 = (data['시간대'] == condition[3])\n",
    "            hierarchy_sample_data[key] = pd.concat([hierarchy_sample_data[key], \n",
    "                                                    data.loc[condition1&condition2&condition3&condition4, :]]).reset_index(drop = True)\n",
    "    return hierarchy_sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "982444df-09b8-407c-981d-17b810785f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>train_data_start_dt</th>\n",
       "      <th>train_data_end_dt</th>\n",
       "      <th>등록일시</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>2022-06-28 01:00:00+00:00</td>\n",
       "      <td>2024-07-19 08:54:31.089964+00:00</td>\n",
       "      <td>2024-07-19 13:39:14.850626+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id       train_data_start_dt                train_data_end_dt  \\\n",
       "0        48 2022-06-28 01:00:00+00:00 2024-07-19 08:54:31.089964+00:00   \n",
       "\n",
       "                              등록일시  \n",
       "0 2024-07-19 13:39:14.850626+00:00  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31b0f5c7-074e-4ada-a09c-7d5f3f7f76cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>예약희망일시</th>\n",
       "      <th>고객_접속일시</th>\n",
       "      <th>고객_접속point</th>\n",
       "      <th>예약희망_point</th>\n",
       "      <th>고객_코드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-01 09:00:00+00:00</td>\n",
       "      <td>2022-06-19 22:28:21.496006+00:00</td>\n",
       "      <td>0101000020E61000006125759E75C85F40532CCFAB3DBD...</td>\n",
       "      <td>0101000020E61000006125759E75C85F40532CCFAB3DBD...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-01 07:00:00+00:00</td>\n",
       "      <td>2022-06-25 05:01:23.216783+00:00</td>\n",
       "      <td>0101000020E61000002FB4A4CBD0C25F405F44093665BF...</td>\n",
       "      <td>0101000020E61000002FB4A4CBD0C25F405F44093665BF...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-01 08:00:00+00:00</td>\n",
       "      <td>2022-06-25 08:36:34.195153+00:00</td>\n",
       "      <td>0101000020E6100000E652EDFFFFBE5F40D7D7AA753DBE...</td>\n",
       "      <td>0101000020E6100000E652EDFFFFBE5F40D7D7AA753DBE...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-01 00:30:00+00:00</td>\n",
       "      <td>2022-06-27 08:37:27.256670+00:00</td>\n",
       "      <td>0101000020E61000004FEE9DBDFDC65F40E07A15FFD7C2...</td>\n",
       "      <td>0101000020E61000004FEE9DBDFDC65F40E07A15FFD7C2...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-01 00:30:00+00:00</td>\n",
       "      <td>2022-06-27 13:31:05.356583+00:00</td>\n",
       "      <td>0101000020E6100000645886C5D7C75F406F54223C8BC0...</td>\n",
       "      <td>0101000020E6100000645886C5D7C75F406F54223C8BC0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62003</th>\n",
       "      <td>2024-07-18 11:00:00+00:00</td>\n",
       "      <td>2024-07-17 09:23:23.784285+00:00</td>\n",
       "      <td>0101000020E610000031DE189B88C15F40F59C6F2776C0...</td>\n",
       "      <td>0101000020E610000031DE189B88C15F40F59C6F2776C0...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62004</th>\n",
       "      <td>2024-07-18 11:30:00+00:00</td>\n",
       "      <td>2024-07-17 09:47:31.481653+00:00</td>\n",
       "      <td>0101000020E61000003C4882FCABC95F40F6BEC5E7B6BF...</td>\n",
       "      <td>0101000020E61000003C4882FCABC95F40F6BEC5E7B6BF...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62005</th>\n",
       "      <td>2024-07-18 08:30:00+00:00</td>\n",
       "      <td>2024-07-17 09:48:37.582923+00:00</td>\n",
       "      <td>0101000020E61000007C1B88E1EAC05F4005D1073707BB...</td>\n",
       "      <td>0101000020E61000007C1B88E1EAC05F4005D1073707BB...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62006</th>\n",
       "      <td>2024-07-18 12:00:00+00:00</td>\n",
       "      <td>2024-07-17 10:12:34.110915+00:00</td>\n",
       "      <td>0101000020E61000008F819CD063C75F40CB1557E39FBF...</td>\n",
       "      <td>0101000020E61000008F819CD063C75F40CB1557E39FBF...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62007</th>\n",
       "      <td>2024-07-18 11:00:00+00:00</td>\n",
       "      <td>2024-07-17 12:16:08.463490+00:00</td>\n",
       "      <td>0101000020E610000044AC6BD413BF5F40A3A68B8479BD...</td>\n",
       "      <td>0101000020E610000044AC6BD413BF5F40A3A68B8479BD...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62008 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         예약희망일시                          고객_접속일시  \\\n",
       "0     2022-07-01 09:00:00+00:00 2022-06-19 22:28:21.496006+00:00   \n",
       "1     2022-07-01 07:00:00+00:00 2022-06-25 05:01:23.216783+00:00   \n",
       "2     2022-07-01 08:00:00+00:00 2022-06-25 08:36:34.195153+00:00   \n",
       "3     2022-07-01 00:30:00+00:00 2022-06-27 08:37:27.256670+00:00   \n",
       "4     2022-07-01 00:30:00+00:00 2022-06-27 13:31:05.356583+00:00   \n",
       "...                         ...                              ...   \n",
       "62003 2024-07-18 11:00:00+00:00 2024-07-17 09:23:23.784285+00:00   \n",
       "62004 2024-07-18 11:30:00+00:00 2024-07-17 09:47:31.481653+00:00   \n",
       "62005 2024-07-18 08:30:00+00:00 2024-07-17 09:48:37.582923+00:00   \n",
       "62006 2024-07-18 12:00:00+00:00 2024-07-17 10:12:34.110915+00:00   \n",
       "62007 2024-07-18 11:00:00+00:00 2024-07-17 12:16:08.463490+00:00   \n",
       "\n",
       "                                              고객_접속point  \\\n",
       "0      0101000020E61000006125759E75C85F40532CCFAB3DBD...   \n",
       "1      0101000020E61000002FB4A4CBD0C25F405F44093665BF...   \n",
       "2      0101000020E6100000E652EDFFFFBE5F40D7D7AA753DBE...   \n",
       "3      0101000020E61000004FEE9DBDFDC65F40E07A15FFD7C2...   \n",
       "4      0101000020E6100000645886C5D7C75F406F54223C8BC0...   \n",
       "...                                                  ...   \n",
       "62003  0101000020E610000031DE189B88C15F40F59C6F2776C0...   \n",
       "62004  0101000020E61000003C4882FCABC95F40F6BEC5E7B6BF...   \n",
       "62005  0101000020E61000007C1B88E1EAC05F4005D1073707BB...   \n",
       "62006  0101000020E61000008F819CD063C75F40CB1557E39FBF...   \n",
       "62007  0101000020E610000044AC6BD413BF5F40A3A68B8479BD...   \n",
       "\n",
       "                                              예약희망_point  고객_코드  \n",
       "0      0101000020E61000006125759E75C85F40532CCFAB3DBD...     70  \n",
       "1      0101000020E61000002FB4A4CBD0C25F405F44093665BF...     53  \n",
       "2      0101000020E6100000E652EDFFFFBE5F40D7D7AA753DBE...     64  \n",
       "3      0101000020E61000004FEE9DBDFDC65F40E07A15FFD7C2...      2  \n",
       "4      0101000020E6100000645886C5D7C75F406F54223C8BC0...      0  \n",
       "...                                                  ...    ...  \n",
       "62003  0101000020E610000031DE189B88C15F40F59C6F2776C0...     72  \n",
       "62004  0101000020E61000003C4882FCABC95F40F6BEC5E7B6BF...     76  \n",
       "62005  0101000020E61000007C1B88E1EAC05F4005D1073707BB...     43  \n",
       "62006  0101000020E61000008F819CD063C75F40CB1557E39FBF...     80  \n",
       "62007  0101000020E610000044AC6BD413BF5F40A3A68B8479BD...     75  \n",
       "\n",
       "[62008 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3f7ad75-db43-4261-ada5-a1f10a113737",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>예약희망일시</th>\n",
       "      <th>고객_접속일시</th>\n",
       "      <th>고객_접속point</th>\n",
       "      <th>예약희망_point</th>\n",
       "      <th>고객_코드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-01 09:00:00+00:00</td>\n",
       "      <td>2022-06-19 22:28:21.496006+00:00</td>\n",
       "      <td>0101000020E61000006125759E75C85F40532CCFAB3DBD...</td>\n",
       "      <td>0101000020E61000006125759E75C85F40532CCFAB3DBD...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-01 07:00:00+00:00</td>\n",
       "      <td>2022-06-25 05:01:23.216783+00:00</td>\n",
       "      <td>0101000020E61000002FB4A4CBD0C25F405F44093665BF...</td>\n",
       "      <td>0101000020E61000002FB4A4CBD0C25F405F44093665BF...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-01 08:00:00+00:00</td>\n",
       "      <td>2022-06-25 08:36:34.195153+00:00</td>\n",
       "      <td>0101000020E6100000E652EDFFFFBE5F40D7D7AA753DBE...</td>\n",
       "      <td>0101000020E6100000E652EDFFFFBE5F40D7D7AA753DBE...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-01 00:30:00+00:00</td>\n",
       "      <td>2022-06-27 08:37:27.256670+00:00</td>\n",
       "      <td>0101000020E61000004FEE9DBDFDC65F40E07A15FFD7C2...</td>\n",
       "      <td>0101000020E61000004FEE9DBDFDC65F40E07A15FFD7C2...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-01 00:30:00+00:00</td>\n",
       "      <td>2022-06-27 13:31:05.356583+00:00</td>\n",
       "      <td>0101000020E6100000645886C5D7C75F406F54223C8BC0...</td>\n",
       "      <td>0101000020E6100000645886C5D7C75F406F54223C8BC0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62003</th>\n",
       "      <td>2024-07-18 11:00:00+00:00</td>\n",
       "      <td>2024-07-17 09:23:23.784285+00:00</td>\n",
       "      <td>0101000020E610000031DE189B88C15F40F59C6F2776C0...</td>\n",
       "      <td>0101000020E610000031DE189B88C15F40F59C6F2776C0...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62004</th>\n",
       "      <td>2024-07-18 11:30:00+00:00</td>\n",
       "      <td>2024-07-17 09:47:31.481653+00:00</td>\n",
       "      <td>0101000020E61000003C4882FCABC95F40F6BEC5E7B6BF...</td>\n",
       "      <td>0101000020E61000003C4882FCABC95F40F6BEC5E7B6BF...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62005</th>\n",
       "      <td>2024-07-18 08:30:00+00:00</td>\n",
       "      <td>2024-07-17 09:48:37.582923+00:00</td>\n",
       "      <td>0101000020E61000007C1B88E1EAC05F4005D1073707BB...</td>\n",
       "      <td>0101000020E61000007C1B88E1EAC05F4005D1073707BB...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62006</th>\n",
       "      <td>2024-07-18 12:00:00+00:00</td>\n",
       "      <td>2024-07-17 10:12:34.110915+00:00</td>\n",
       "      <td>0101000020E61000008F819CD063C75F40CB1557E39FBF...</td>\n",
       "      <td>0101000020E61000008F819CD063C75F40CB1557E39FBF...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62007</th>\n",
       "      <td>2024-07-18 11:00:00+00:00</td>\n",
       "      <td>2024-07-17 12:16:08.463490+00:00</td>\n",
       "      <td>0101000020E610000044AC6BD413BF5F40A3A68B8479BD...</td>\n",
       "      <td>0101000020E610000044AC6BD413BF5F40A3A68B8479BD...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62008 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         예약희망일시                          고객_접속일시  \\\n",
       "0     2022-07-01 09:00:00+00:00 2022-06-19 22:28:21.496006+00:00   \n",
       "1     2022-07-01 07:00:00+00:00 2022-06-25 05:01:23.216783+00:00   \n",
       "2     2022-07-01 08:00:00+00:00 2022-06-25 08:36:34.195153+00:00   \n",
       "3     2022-07-01 00:30:00+00:00 2022-06-27 08:37:27.256670+00:00   \n",
       "4     2022-07-01 00:30:00+00:00 2022-06-27 13:31:05.356583+00:00   \n",
       "...                         ...                              ...   \n",
       "62003 2024-07-18 11:00:00+00:00 2024-07-17 09:23:23.784285+00:00   \n",
       "62004 2024-07-18 11:30:00+00:00 2024-07-17 09:47:31.481653+00:00   \n",
       "62005 2024-07-18 08:30:00+00:00 2024-07-17 09:48:37.582923+00:00   \n",
       "62006 2024-07-18 12:00:00+00:00 2024-07-17 10:12:34.110915+00:00   \n",
       "62007 2024-07-18 11:00:00+00:00 2024-07-17 12:16:08.463490+00:00   \n",
       "\n",
       "                                              고객_접속point  \\\n",
       "0      0101000020E61000006125759E75C85F40532CCFAB3DBD...   \n",
       "1      0101000020E61000002FB4A4CBD0C25F405F44093665BF...   \n",
       "2      0101000020E6100000E652EDFFFFBE5F40D7D7AA753DBE...   \n",
       "3      0101000020E61000004FEE9DBDFDC65F40E07A15FFD7C2...   \n",
       "4      0101000020E6100000645886C5D7C75F406F54223C8BC0...   \n",
       "...                                                  ...   \n",
       "62003  0101000020E610000031DE189B88C15F40F59C6F2776C0...   \n",
       "62004  0101000020E61000003C4882FCABC95F40F6BEC5E7B6BF...   \n",
       "62005  0101000020E61000007C1B88E1EAC05F4005D1073707BB...   \n",
       "62006  0101000020E61000008F819CD063C75F40CB1557E39FBF...   \n",
       "62007  0101000020E610000044AC6BD413BF5F40A3A68B8479BD...   \n",
       "\n",
       "                                              예약희망_point  고객_코드  \n",
       "0      0101000020E61000006125759E75C85F40532CCFAB3DBD...     70  \n",
       "1      0101000020E61000002FB4A4CBD0C25F405F44093665BF...     53  \n",
       "2      0101000020E6100000E652EDFFFFBE5F40D7D7AA753DBE...     64  \n",
       "3      0101000020E61000004FEE9DBDFDC65F40E07A15FFD7C2...      2  \n",
       "4      0101000020E6100000645886C5D7C75F406F54223C8BC0...      0  \n",
       "...                                                  ...    ...  \n",
       "62003  0101000020E610000031DE189B88C15F40F59C6F2776C0...     72  \n",
       "62004  0101000020E61000003C4882FCABC95F40F6BEC5E7B6BF...     76  \n",
       "62005  0101000020E61000007C1B88E1EAC05F4005D1073707BB...     43  \n",
       "62006  0101000020E61000008F819CD063C75F40CB1557E39FBF...     80  \n",
       "62007  0101000020E610000044AC6BD413BF5F40A3A68B8479BD...     75  \n",
       "\n",
       "[62008 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103580bc-ca24-4b3d-9b0b-037244ceefb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id, cluster_num, drift_method, drift_value, drift_yn, logical_dt, 적재일시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed34ec5-6ac3-40a0-8c5f-a0cb2352cce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_make_data_3",
   "language": "python",
   "name": "test_make_data_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
